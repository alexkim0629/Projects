{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "author: Alex Kim\n",
    "date: November 6, 2024\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyday, millions if not billions of credit card transactions are processed across the world. Banks across the world have a crucial responsibilty of confirming the legitimacy of every transaction in order to prevent fraud. The danger of fraudulent transactions are constantly present as bad actors often try to take advantage of weaknesses in order to gain money. In today's digitized world, making sure that every transaction is authentic and legitimate is extremely important for maintaining consumer trust and financial security. As a data scientist at a banking institution issuing credit cards, my task is to develop an automated fraud detector model. This model will analyze transcation data and identify the credit transaction as fraudulent or genuine. An important thing to note that is that the model should appropriately balance false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# model tuning and preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Model metric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    fbeta_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To successfully develop an automated fraud detection/classification model, histroical data of credit card transactions, including whether or not they were fraudulent, will be primarily used. The data that will be used for developing the model are transactions made by credit cards in September 2013 by European cardholders made available on Kaggle. The data was collected and analyzed by Worldline and the Machine Learning Group of ULB (Universit√© Libre de Bruxelles), specifically during their research collaboration on big data mining and fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "#### Response\n",
    "* **Fraud** [int64]: status of the transaction. 1 indicates a fraudulent transaction and 0 indicates not fraud, a genuine transaction.\n",
    "\n",
    "#### Feature\n",
    "* **Amount** [float64]: amount (in dollars) of the transaction.\n",
    "* **PC01 - PC28** [float64]: the 28 principal components that encode information such as location and type of purchase while preserving customer privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC01</th>\n",
       "      <th>PC02</th>\n",
       "      <th>PC03</th>\n",
       "      <th>PC04</th>\n",
       "      <th>PC05</th>\n",
       "      <th>PC06</th>\n",
       "      <th>PC07</th>\n",
       "      <th>PC08</th>\n",
       "      <th>PC09</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.702080</td>\n",
       "      <td>-3.315274</td>\n",
       "      <td>0.612866</td>\n",
       "      <td>2.414363</td>\n",
       "      <td>-1.884599</td>\n",
       "      <td>1.514794</td>\n",
       "      <td>0.131483</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>1.568789</td>\n",
       "      <td>-0.869887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496013</td>\n",
       "      <td>-0.096228</td>\n",
       "      <td>-0.924270</td>\n",
       "      <td>-0.175346</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>-0.272192</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.192446</td>\n",
       "      <td>927.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.690580</td>\n",
       "      <td>1.286872</td>\n",
       "      <td>1.629988</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.061507</td>\n",
       "      <td>-0.546067</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>-0.007774</td>\n",
       "      <td>0.773795</td>\n",
       "      <td>-0.212306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355172</td>\n",
       "      <td>-0.665155</td>\n",
       "      <td>-0.021777</td>\n",
       "      <td>0.254960</td>\n",
       "      <td>-0.185833</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.347278</td>\n",
       "      <td>0.163613</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.969394</td>\n",
       "      <td>-0.253345</td>\n",
       "      <td>-1.611232</td>\n",
       "      <td>0.627206</td>\n",
       "      <td>0.429682</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>-0.174938</td>\n",
       "      <td>-0.095031</td>\n",
       "      <td>1.111306</td>\n",
       "      <td>-0.654715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140268</td>\n",
       "      <td>0.839200</td>\n",
       "      <td>-0.180253</td>\n",
       "      <td>0.090653</td>\n",
       "      <td>0.375609</td>\n",
       "      <td>0.856089</td>\n",
       "      <td>-0.023358</td>\n",
       "      <td>-0.030589</td>\n",
       "      <td>49.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.553788</td>\n",
       "      <td>1.435771</td>\n",
       "      <td>-0.791836</td>\n",
       "      <td>-0.512074</td>\n",
       "      <td>0.937930</td>\n",
       "      <td>-0.567430</td>\n",
       "      <td>0.683134</td>\n",
       "      <td>0.310608</td>\n",
       "      <td>-0.070914</td>\n",
       "      <td>-1.480662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.267238</td>\n",
       "      <td>-0.383380</td>\n",
       "      <td>-1.063272</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>0.644840</td>\n",
       "      <td>0.257065</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.503234</td>\n",
       "      <td>0.520610</td>\n",
       "      <td>0.591397</td>\n",
       "      <td>1.054720</td>\n",
       "      <td>1.306610</td>\n",
       "      <td>-1.392141</td>\n",
       "      <td>0.421473</td>\n",
       "      <td>-0.274220</td>\n",
       "      <td>-0.718293</td>\n",
       "      <td>-0.520577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027699</td>\n",
       "      <td>0.122597</td>\n",
       "      <td>-0.096967</td>\n",
       "      <td>0.334576</td>\n",
       "      <td>-0.174797</td>\n",
       "      <td>0.446997</td>\n",
       "      <td>-0.311952</td>\n",
       "      <td>0.437133</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67840</th>\n",
       "      <td>-0.815702</td>\n",
       "      <td>1.250443</td>\n",
       "      <td>1.235399</td>\n",
       "      <td>0.798663</td>\n",
       "      <td>-0.104867</td>\n",
       "      <td>-0.198403</td>\n",
       "      <td>0.468914</td>\n",
       "      <td>0.187117</td>\n",
       "      <td>-0.404717</td>\n",
       "      <td>-0.090196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.270789</td>\n",
       "      <td>-0.066755</td>\n",
       "      <td>0.052279</td>\n",
       "      <td>-0.366833</td>\n",
       "      <td>-0.435550</td>\n",
       "      <td>-0.376964</td>\n",
       "      <td>-0.147660</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67841</th>\n",
       "      <td>-3.517229</td>\n",
       "      <td>3.326821</td>\n",
       "      <td>-3.590262</td>\n",
       "      <td>0.674769</td>\n",
       "      <td>-0.679266</td>\n",
       "      <td>-0.469516</td>\n",
       "      <td>-1.135362</td>\n",
       "      <td>2.778095</td>\n",
       "      <td>-2.404956</td>\n",
       "      <td>0.378914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455767</td>\n",
       "      <td>0.388102</td>\n",
       "      <td>0.268986</td>\n",
       "      <td>0.382692</td>\n",
       "      <td>-0.653335</td>\n",
       "      <td>2.192962</td>\n",
       "      <td>-0.953907</td>\n",
       "      <td>-0.137082</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67842</th>\n",
       "      <td>2.138450</td>\n",
       "      <td>-0.001148</td>\n",
       "      <td>-1.778731</td>\n",
       "      <td>0.076097</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>-0.512793</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>-0.280997</td>\n",
       "      <td>0.585802</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193403</td>\n",
       "      <td>0.708043</td>\n",
       "      <td>-0.060317</td>\n",
       "      <td>0.076972</td>\n",
       "      <td>0.398423</td>\n",
       "      <td>-0.099414</td>\n",
       "      <td>-0.023301</td>\n",
       "      <td>-0.058588</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67843</th>\n",
       "      <td>-2.639999</td>\n",
       "      <td>3.023083</td>\n",
       "      <td>-1.028799</td>\n",
       "      <td>3.095028</td>\n",
       "      <td>1.612154</td>\n",
       "      <td>1.002180</td>\n",
       "      <td>0.584766</td>\n",
       "      <td>0.545651</td>\n",
       "      <td>-1.380780</td>\n",
       "      <td>0.679444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123887</td>\n",
       "      <td>-0.576202</td>\n",
       "      <td>0.136905</td>\n",
       "      <td>-1.426640</td>\n",
       "      <td>-0.822473</td>\n",
       "      <td>-0.427101</td>\n",
       "      <td>-2.163853</td>\n",
       "      <td>-0.553031</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67844</th>\n",
       "      <td>-1.340224</td>\n",
       "      <td>-0.099470</td>\n",
       "      <td>2.569205</td>\n",
       "      <td>-1.023849</td>\n",
       "      <td>0.266961</td>\n",
       "      <td>-0.992928</td>\n",
       "      <td>0.664708</td>\n",
       "      <td>-0.141592</td>\n",
       "      <td>0.075265</td>\n",
       "      <td>-0.986827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.186024</td>\n",
       "      <td>-0.010211</td>\n",
       "      <td>0.359903</td>\n",
       "      <td>0.314488</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>-0.235308</td>\n",
       "      <td>-0.149792</td>\n",
       "      <td>82.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67845 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC01      PC02      PC03      PC04      PC05      PC06      PC07  \\\n",
       "0     -0.702080 -3.315274  0.612866  2.414363 -1.884599  1.514794  0.131483   \n",
       "1     -0.690580  1.286872  1.629988  0.002150  0.061507 -0.546067  0.508168   \n",
       "2      1.969394 -0.253345 -1.611232  0.627206  0.429682  0.178193 -0.174938   \n",
       "3     -0.553788  1.435771 -0.791836 -0.512074  0.937930 -0.567430  0.683134   \n",
       "4     -1.503234  0.520610  0.591397  1.054720  1.306610 -1.392141  0.421473   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "67840 -0.815702  1.250443  1.235399  0.798663 -0.104867 -0.198403  0.468914   \n",
       "67841 -3.517229  3.326821 -3.590262  0.674769 -0.679266 -0.469516 -1.135362   \n",
       "67842  2.138450 -0.001148 -1.778731  0.076097  0.618824 -0.512793  0.206600   \n",
       "67843 -2.639999  3.023083 -1.028799  3.095028  1.612154  1.002180  0.584766   \n",
       "67844 -1.340224 -0.099470  2.569205 -1.023849  0.266961 -0.992928  0.664708   \n",
       "\n",
       "           PC08      PC09      PC10  ...      PC21      PC22      PC23  \\\n",
       "0      0.225408  1.568789 -0.869887  ...  0.496013 -0.096228 -0.924270   \n",
       "1     -0.007774  0.773795 -0.212306  ... -0.355172 -0.665155 -0.021777   \n",
       "2     -0.095031  1.111306 -0.654715  ...  0.140268  0.839200 -0.180253   \n",
       "3      0.310608 -0.070914 -1.480662  ... -0.000774  0.267238 -0.383380   \n",
       "4     -0.274220 -0.718293 -0.520577  ... -0.027699  0.122597 -0.096967   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "67840  0.187117 -0.404717 -0.090196  ...  0.099021  0.270789 -0.066755   \n",
       "67841  2.778095 -2.404956  0.378914  ...  0.455767  0.388102  0.268986   \n",
       "67842 -0.280997  0.585802 -0.000395  ...  0.193403  0.708043 -0.060317   \n",
       "67843  0.545651 -1.380780  0.679444  ... -0.123887 -0.576202  0.136905   \n",
       "67844 -0.141592  0.075265 -0.986827  ...  0.029485 -0.186024 -0.010211   \n",
       "\n",
       "           PC24      PC25      PC26      PC27      PC28  Amount  Fraud  \n",
       "0     -0.175346  0.206700 -0.272192 -0.046401  0.192446  927.61      0  \n",
       "1      0.254960 -0.185833  0.019074  0.347278  0.163613    3.57      0  \n",
       "2      0.090653  0.375609  0.856089 -0.023358 -0.030589   49.32      0  \n",
       "3     -1.063272 -0.012404  0.644840  0.257065  0.191257    1.41      0  \n",
       "4      0.334576 -0.174797  0.446997 -0.311952  0.437133    0.76      0  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "67840  0.052279 -0.366833 -0.435550 -0.376964 -0.147660   19.99      0  \n",
       "67841  0.382692 -0.653335  2.192962 -0.953907 -0.137082    0.76      0  \n",
       "67842  0.076972  0.398423 -0.099414 -0.023301 -0.058588    1.00      0  \n",
       "67843 -1.426640 -0.822473 -0.427101 -2.163853 -0.553031    4.01      0  \n",
       "67844  0.359903  0.314488  0.083369 -0.235308 -0.149792   82.12      0  \n",
       "\n",
       "[67845 rows x 30 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "fraud = pd.read_parquet(\"https://cs307.org/lab-07/data/fraud.parquet\")\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC01</th>\n",
       "      <th>PC02</th>\n",
       "      <th>PC03</th>\n",
       "      <th>PC04</th>\n",
       "      <th>PC05</th>\n",
       "      <th>PC06</th>\n",
       "      <th>PC07</th>\n",
       "      <th>PC08</th>\n",
       "      <th>PC09</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57638</th>\n",
       "      <td>-0.514509</td>\n",
       "      <td>0.899378</td>\n",
       "      <td>1.627215</td>\n",
       "      <td>-0.142250</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>-0.235422</td>\n",
       "      <td>0.482540</td>\n",
       "      <td>0.247403</td>\n",
       "      <td>-0.562327</td>\n",
       "      <td>-0.166813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143290</td>\n",
       "      <td>-0.390205</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.184779</td>\n",
       "      <td>-0.348711</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.107938</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27686</th>\n",
       "      <td>-0.813568</td>\n",
       "      <td>-0.373893</td>\n",
       "      <td>1.152977</td>\n",
       "      <td>-0.449774</td>\n",
       "      <td>-3.868866</td>\n",
       "      <td>2.780636</td>\n",
       "      <td>3.654192</td>\n",
       "      <td>-0.672442</td>\n",
       "      <td>0.753230</td>\n",
       "      <td>-0.662803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376783</td>\n",
       "      <td>-0.004239</td>\n",
       "      <td>0.074801</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>-0.448493</td>\n",
       "      <td>0.861423</td>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.711632</td>\n",
       "      <td>798.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13321</th>\n",
       "      <td>-2.443142</td>\n",
       "      <td>3.258831</td>\n",
       "      <td>-0.791511</td>\n",
       "      <td>0.223548</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>-1.263044</td>\n",
       "      <td>1.220214</td>\n",
       "      <td>-0.418068</td>\n",
       "      <td>1.860453</td>\n",
       "      <td>4.184883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348587</td>\n",
       "      <td>0.531679</td>\n",
       "      <td>0.058990</td>\n",
       "      <td>0.371638</td>\n",
       "      <td>-0.207398</td>\n",
       "      <td>-0.505837</td>\n",
       "      <td>0.524542</td>\n",
       "      <td>-0.343895</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28308</th>\n",
       "      <td>-0.397300</td>\n",
       "      <td>0.922104</td>\n",
       "      <td>1.224699</td>\n",
       "      <td>-0.334974</td>\n",
       "      <td>0.322603</td>\n",
       "      <td>-0.117372</td>\n",
       "      <td>0.534683</td>\n",
       "      <td>0.175550</td>\n",
       "      <td>-0.486404</td>\n",
       "      <td>-0.120147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239303</td>\n",
       "      <td>-0.695001</td>\n",
       "      <td>-0.128231</td>\n",
       "      <td>-0.536463</td>\n",
       "      <td>-0.138971</td>\n",
       "      <td>0.107526</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54252</th>\n",
       "      <td>1.994046</td>\n",
       "      <td>-0.367813</td>\n",
       "      <td>-0.462867</td>\n",
       "      <td>0.338661</td>\n",
       "      <td>-0.485326</td>\n",
       "      <td>-0.241576</td>\n",
       "      <td>-0.590987</td>\n",
       "      <td>0.089319</td>\n",
       "      <td>1.413224</td>\n",
       "      <td>-0.149292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196388</td>\n",
       "      <td>-0.484457</td>\n",
       "      <td>0.421867</td>\n",
       "      <td>0.601393</td>\n",
       "      <td>-0.448014</td>\n",
       "      <td>-0.646256</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>-0.027244</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49499</th>\n",
       "      <td>-0.033583</td>\n",
       "      <td>-0.487672</td>\n",
       "      <td>1.435406</td>\n",
       "      <td>-2.759369</td>\n",
       "      <td>-1.785638</td>\n",
       "      <td>0.402364</td>\n",
       "      <td>-2.306038</td>\n",
       "      <td>-2.287179</td>\n",
       "      <td>0.129717</td>\n",
       "      <td>-1.036412</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.286823</td>\n",
       "      <td>0.824100</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.301618</td>\n",
       "      <td>0.081215</td>\n",
       "      <td>0.163422</td>\n",
       "      <td>0.252456</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29250</th>\n",
       "      <td>-0.731245</td>\n",
       "      <td>1.151677</td>\n",
       "      <td>0.912393</td>\n",
       "      <td>-0.653540</td>\n",
       "      <td>0.700577</td>\n",
       "      <td>-0.461372</td>\n",
       "      <td>1.093273</td>\n",
       "      <td>-0.126254</td>\n",
       "      <td>-0.339171</td>\n",
       "      <td>-0.467356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368185</td>\n",
       "      <td>-0.991854</td>\n",
       "      <td>-0.376461</td>\n",
       "      <td>-0.661608</td>\n",
       "      <td>0.554237</td>\n",
       "      <td>0.450650</td>\n",
       "      <td>0.076395</td>\n",
       "      <td>0.096252</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>2.135923</td>\n",
       "      <td>-0.714182</td>\n",
       "      <td>-1.842502</td>\n",
       "      <td>-0.587267</td>\n",
       "      <td>0.090754</td>\n",
       "      <td>-0.465733</td>\n",
       "      <td>-0.024834</td>\n",
       "      <td>-0.328747</td>\n",
       "      <td>-0.659832</td>\n",
       "      <td>0.853241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537267</td>\n",
       "      <td>-1.081138</td>\n",
       "      <td>0.196589</td>\n",
       "      <td>0.087797</td>\n",
       "      <td>-0.111583</td>\n",
       "      <td>0.479888</td>\n",
       "      <td>-0.082523</td>\n",
       "      <td>-0.053305</td>\n",
       "      <td>64.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14898</th>\n",
       "      <td>-0.335632</td>\n",
       "      <td>0.939736</td>\n",
       "      <td>-2.961515</td>\n",
       "      <td>-1.224739</td>\n",
       "      <td>4.446891</td>\n",
       "      <td>2.352092</td>\n",
       "      <td>0.789725</td>\n",
       "      <td>0.609460</td>\n",
       "      <td>-0.746845</td>\n",
       "      <td>-1.580751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>-0.428325</td>\n",
       "      <td>0.536043</td>\n",
       "      <td>0.278736</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>-0.069295</td>\n",
       "      <td>0.051891</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27636</th>\n",
       "      <td>-1.444958</td>\n",
       "      <td>1.264710</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>-0.607371</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.264429</td>\n",
       "      <td>-0.246528</td>\n",
       "      <td>0.703092</td>\n",
       "      <td>0.374768</td>\n",
       "      <td>-0.493145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271551</td>\n",
       "      <td>1.072854</td>\n",
       "      <td>-0.449656</td>\n",
       "      <td>0.122150</td>\n",
       "      <td>0.209835</td>\n",
       "      <td>-0.081948</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>-0.131398</td>\n",
       "      <td>7.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54276 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC01      PC02      PC03      PC04      PC05      PC06      PC07  \\\n",
       "57638 -0.514509  0.899378  1.627215 -0.142250  0.005250 -0.235422  0.482540   \n",
       "27686 -0.813568 -0.373893  1.152977 -0.449774 -3.868866  2.780636  3.654192   \n",
       "13321 -2.443142  3.258831 -0.791511  0.223548  0.007932 -1.263044  1.220214   \n",
       "28308 -0.397300  0.922104  1.224699 -0.334974  0.322603 -0.117372  0.534683   \n",
       "54252  1.994046 -0.367813 -0.462867  0.338661 -0.485326 -0.241576 -0.590987   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49499 -0.033583 -0.487672  1.435406 -2.759369 -1.785638  0.402364 -2.306038   \n",
       "29250 -0.731245  1.151677  0.912393 -0.653540  0.700577 -0.461372  1.093273   \n",
       "31586  2.135923 -0.714182 -1.842502 -0.587267  0.090754 -0.465733 -0.024834   \n",
       "14898 -0.335632  0.939736 -2.961515 -1.224739  4.446891  2.352092  0.789725   \n",
       "27636 -1.444958  1.264710  0.370500 -0.607371  0.155386  0.264429 -0.246528   \n",
       "\n",
       "           PC08      PC09      PC10  ...      PC21      PC22      PC23  \\\n",
       "57638  0.247403 -0.562327 -0.166813  ... -0.143290 -0.390205  0.030719   \n",
       "27686 -0.672442  0.753230 -0.662803  ... -0.376783 -0.004239  0.074801   \n",
       "13321 -0.418068  1.860453  4.184883  ... -0.348587  0.531679  0.058990   \n",
       "28308  0.175550 -0.486404 -0.120147  ... -0.239303 -0.695001 -0.128231   \n",
       "54252  0.089319  1.413224 -0.149292  ... -0.196388 -0.484457  0.421867   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49499 -2.287179  0.129717 -1.036412  ... -1.286823  0.824100  0.018890   \n",
       "29250 -0.126254 -0.339171 -0.467356  ... -0.368185 -0.991854 -0.376461   \n",
       "31586 -0.328747 -0.659832  0.853241  ... -0.537267 -1.081138  0.196589   \n",
       "14898  0.609460 -0.746845 -1.580751  ... -0.002116  0.009686 -0.428325   \n",
       "27636  0.703092  0.374768 -0.493145  ...  0.271551  1.072854 -0.449656   \n",
       "\n",
       "           PC24      PC25      PC26      PC27      PC28  Amount  Fraud  \n",
       "57638  0.184779 -0.348711  0.073253  0.273217  0.107938    3.59      0  \n",
       "27686  0.124238 -0.448493  0.861423 -0.093639 -0.711632  798.01      0  \n",
       "13321  0.371638 -0.207398 -0.505837  0.524542 -0.343895    1.79      0  \n",
       "28308 -0.536463 -0.138971  0.107526  0.255644  0.100814    2.69      0  \n",
       "54252  0.601393 -0.448014 -0.646256  0.027632 -0.027244    4.49      0  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "49499  0.000018  0.301618  0.081215  0.163422  0.252456   10.00      0  \n",
       "29250 -0.661608  0.554237  0.450650  0.076395  0.096252    6.99      0  \n",
       "31586  0.087797 -0.111583  0.479888 -0.082523 -0.053305   64.90      0  \n",
       "14898  0.536043  0.278736  0.680976 -0.069295  0.051891    0.76      0  \n",
       "27636  0.122150  0.209835 -0.081948  0.034733 -0.131398    7.49      0  \n",
       "\n",
       "[54276 rows x 30 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_train, fraud_test = train_test_split(\n",
    "    fraud,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=fraud[\"Fraud\"],\n",
    ")\n",
    "fraud_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54276\n"
     ]
    }
   ],
   "source": [
    "num_samples = fraud_train.shape[0]\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraud train dataset contains 54276 rows and 30 columns. This tells us that there are 67845 samples and 29 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud\n",
      "0    53961\n",
      "1      315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# summary statistics\n",
    "## Counts\n",
    "label_counts = fraud_train['Fraud'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud\n",
      "0    0.994196\n",
      "1    0.005804\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Proportions\n",
    "proportion_fraud = fraud_train['Fraud'].value_counts(normalize=True).rename(\"proportion\")\n",
    "print(proportion_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fraud        mean         std  median       max\n",
      "0      0   88.065104  241.451144   21.80  10199.44\n",
      "1      1  110.947016  254.978960    6.99   2125.87\n"
     ]
    }
   ],
   "source": [
    "## Amount - Mean, Standard Deviation, Median, and Maximum\n",
    "statistics = fraud_train.groupby('Fraud')['Amount'].agg(['mean', 'std', 'median', 'max']).reset_index()\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean         88.197903\n",
       "std         241.535617\n",
       "median       21.690000\n",
       "max       10199.440000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_stats = fraud_train['Amount'].agg(['mean', 'std', 'median', 'max'])\n",
    "none_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizations - fraud vs amount \n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=fraud_train, x='Fraud', y='Amount')\n",
    "plt.title(\"Box Plot of Amount by Fraud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot above shows the distribution and spread of the Amount variable for both Fraud and Not Fraud cases. It is very clear that there are unsually high number of Amount that are considered 'Not Fraud' compared to that are considered 'Fraud'. From this, we could assume that \"bad\" actors usually do not go for unusually high or large amount of money, as it would be easily noticable and put them at risk. We can further assume that 'bad' actors may stay and target at a certain range of value in order to blend in with normal transactions as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data for ML\n",
    "# create X and y for train\n",
    "X_train = fraud_train.drop(\"Fraud\", axis=1)\n",
    "y_train = fraud_train[\"Fraud\"]\n",
    "\n",
    "# create X and y for test\n",
    "X_test = fraud_test.drop(\"Fraud\", axis=1)\n",
    "y_test = fraud_test[\"Fraud\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "# note numeric features\n",
    "numeric_features = X_train.iloc[:, 1:]\n",
    "\n",
    "# define pipeline for numeric\n",
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"MedianImputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"Standardize\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"NumericProcessing\", numeric_preprocessor, numeric_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# class weights\n",
    "weights_list = [\n",
    "    {0: 1, 1: 1},\n",
    "    {0: 1, 1: 2},\n",
    "    \"balanced\",\n",
    "]\n",
    "\n",
    "# scoring metric\n",
    "scoring = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"f1\": make_scorer(fbeta_score, beta=1),\n",
    "\n",
    "}\n",
    "\n",
    "# define parameter grid\n",
    "rf_param_grid = {\n",
    "    \"classifier__n_estimators\": [125, 175],\n",
    "    \"classifier__max_depth\": [5,10],\n",
    "    \"classifier__class_weight\": weights_list,\n",
    "}\n",
    "\n",
    "# create pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "       (\"Preprocessor\", preprocessor),\n",
    "       (\"classifier\", rf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# create GridSearchCV object\n",
    "rf_grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;Preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;NumericProcessing&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;MedianImputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                         (&#x27;Standardize&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index([&#x27;PC01&#x27;, &#x27;PC02&#x27;, &#x27;PC03&#x27;, &#x27;PC04&#x27;, &#x27;PC05&#x27;, &#x27;PC06&#x27;, &#x27;PC07&#x27;, &#x27;PC08&#x27;, &#x27;PC09&#x27;,\n",
       "       &#x27;PC10&#x27;, &#x27;PC11&#x27;, &#x27;PC12&#x27;, &#x27;PC13&#x27;, &#x27;PC14&#x27;, &#x27;PC15&#x27;, &#x27;PC16&#x27;, &#x27;PC17&#x27;, &#x27;PC18&#x27;,\n",
       "       &#x27;P...\n",
       "                         &#x27;classifier__max_depth&#x27;: [5, 10],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [125, 175]},\n",
       "             refit=&#x27;f1&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1&#x27;: make_scorer(fbeta_score, response_method=&#x27;predict&#x27;, beta=1),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, zero_division=0),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;Preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;NumericProcessing&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;MedianImputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                         (&#x27;Standardize&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index([&#x27;PC01&#x27;, &#x27;PC02&#x27;, &#x27;PC03&#x27;, &#x27;PC04&#x27;, &#x27;PC05&#x27;, &#x27;PC06&#x27;, &#x27;PC07&#x27;, &#x27;PC08&#x27;, &#x27;PC09&#x27;,\n",
       "       &#x27;PC10&#x27;, &#x27;PC11&#x27;, &#x27;PC12&#x27;, &#x27;PC13&#x27;, &#x27;PC14&#x27;, &#x27;PC15&#x27;, &#x27;PC16&#x27;, &#x27;PC17&#x27;, &#x27;PC18&#x27;,\n",
       "       &#x27;P...\n",
       "                         &#x27;classifier__max_depth&#x27;: [5, 10],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [125, 175]},\n",
       "             refit=&#x27;f1&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1&#x27;: make_scorer(fbeta_score, response_method=&#x27;predict&#x27;, beta=1),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, zero_division=0),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;NumericProcessing&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;MedianImputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;Standardize&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index([&#x27;PC01&#x27;, &#x27;PC02&#x27;, &#x27;PC03&#x27;, &#x27;PC04&#x27;, &#x27;PC05&#x27;, &#x27;PC06&#x27;, &#x27;PC07&#x27;, &#x27;PC08&#x27;, &#x27;PC09&#x27;,\n",
       "       &#x27;PC10&#x27;, &#x27;PC11&#x27;, &#x27;PC12&#x27;, &#x27;PC13&#x27;, &#x27;PC14&#x27;, &#x27;PC15&#x27;, &#x27;PC16&#x27;, &#x27;PC17&#x27;, &#x27;PC18&#x27;,\n",
       "       &#x27;PC19&#x27;, &#x27;PC20&#x27;, &#x27;PC21&#x27;, &#x27;PC22&#x27;, &#x27;PC23&#x27;, &#x27;PC24&#x27;, &#x27;PC25&#x27;, &#x27;PC26&#x27;, &#x27;PC27&#x27;,\n",
       "       &#x27;PC28&#x27;, &#x27;Amount&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10,\n",
       "                                        n_estimators=125, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;NumericProcessing&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;MedianImputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;Standardize&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 Index([&#x27;PC01&#x27;, &#x27;PC02&#x27;, &#x27;PC03&#x27;, &#x27;PC04&#x27;, &#x27;PC05&#x27;, &#x27;PC06&#x27;, &#x27;PC07&#x27;, &#x27;PC08&#x27;, &#x27;PC09&#x27;,\n",
       "       &#x27;PC10&#x27;, &#x27;PC11&#x27;, &#x27;PC12&#x27;, &#x27;PC13&#x27;, &#x27;PC14&#x27;, &#x27;PC15&#x27;, &#x27;PC16&#x27;, &#x27;PC17&#x27;, &#x27;PC18&#x27;,\n",
       "       &#x27;PC19&#x27;, &#x27;PC20&#x27;, &#x27;PC21&#x27;, &#x27;PC22&#x27;, &#x27;PC23&#x27;, &#x27;PC24&#x27;, &#x27;PC25&#x27;, &#x27;PC26&#x27;, &#x27;PC27&#x27;,\n",
       "       &#x27;PC28&#x27;, &#x27;Amount&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">NumericProcessing</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;PC01&#x27;, &#x27;PC02&#x27;, &#x27;PC03&#x27;, &#x27;PC04&#x27;, &#x27;PC05&#x27;, &#x27;PC06&#x27;, &#x27;PC07&#x27;, &#x27;PC08&#x27;, &#x27;PC09&#x27;,\n",
       "       &#x27;PC10&#x27;, &#x27;PC11&#x27;, &#x27;PC12&#x27;, &#x27;PC13&#x27;, &#x27;PC14&#x27;, &#x27;PC15&#x27;, &#x27;PC16&#x27;, &#x27;PC17&#x27;, &#x27;PC18&#x27;,\n",
       "       &#x27;PC19&#x27;, &#x27;PC20&#x27;, &#x27;PC21&#x27;, &#x27;PC22&#x27;, &#x27;PC23&#x27;, &#x27;PC24&#x27;, &#x27;PC25&#x27;, &#x27;PC26&#x27;, &#x27;PC27&#x27;,\n",
       "       &#x27;PC28&#x27;, &#x27;Amount&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, n_estimators=125,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('Preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('NumericProcessing',\n",
       "                                                                         Pipeline(steps=[('MedianImputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('Standardize',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['PC01', 'PC02', 'PC03', 'PC04', 'PC05', 'PC06', 'PC07', 'PC08', 'PC09',\n",
       "       'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18',\n",
       "       'P...\n",
       "                         'classifier__max_depth': [5, 10],\n",
       "                         'classifier__n_estimators': [125, 175]},\n",
       "             refit='f1',\n",
       "             scoring={'accuracy': make_scorer(accuracy_score, response_method='predict'),\n",
       "                      'f1': make_scorer(fbeta_score, response_method='predict', beta=1),\n",
       "                      'precision': make_scorer(precision_score, response_method='predict', zero_division=0),\n",
       "                      'recall': make_scorer(recall_score, response_method='predict')})"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search object on the training data\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found with cross-validation:\n",
      "{'classifier__class_weight': 'balanced', 'classifier__max_depth': 10, 'classifier__n_estimators': 125}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters found with cross-validation:\")\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99541204, 0.00458796],\n",
       "       [0.98363721, 0.01636279],\n",
       "       [0.99879558, 0.00120442],\n",
       "       [0.99739495, 0.00260505],\n",
       "       [0.99809134, 0.00190866],\n",
       "       [0.99729367, 0.00270633],\n",
       "       [0.99236881, 0.00763119],\n",
       "       [0.99696925, 0.00303075],\n",
       "       [0.99549629, 0.00450371],\n",
       "       [0.99839562, 0.00160438]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.predict_proba(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using the best model\n",
    "y_pred = rf_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9988945390227725\n",
      "Test Precision: 0.9848484848484849\n",
      "Test Recall: 0.8227848101265823\n"
     ]
    }
   ],
   "source": [
    "# report model metrics\n",
    "# calculate test metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraud detection/classification model achieves a test precision of 0.9848 and test recall of 0.8227."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is more important, precision or recall? (The performance cutoffs above suggest an answer to this question, but you do not necessarily need to agree with it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the development process of the model that detects and classifies fraud transactions, I developed a model that achieves a test precision of 0.9848 and test accuracy of 0.8227. These results tells us that the model performs generally well.  A precision of 0.9848 indicates that the model perfroms very well when it comes to reducing false positives. It means that the model very reliable when it comes to predicting transactions as fraudulent. The high precision also suggests that the model is almost always correct when it identifies a transaction as fraud. Furthermore, a recall of 0.8227 indicates that the model can correctly identify about 82% of the fraudulent transactions. But, this also tells us that it incorrectly identifies about 18% of the fraudulent transactions, which can bring about detrimental impact when it comes to credit fraud.\n",
    "\n",
    "Both precision and recall are important evaluation metrics used to assess the model's overall performance in detecting fraudulent transactions. After careful evaluation, the model brings about exceptionally high precision, but a adequte and fair recall. Although the model was generally successful in preventing false positives, we discovered that it is still unable to detect some fraudulent transactions, which was roughly about 18% of the fraudlent transactions. It could be said that recall is more important to consider in high-stake situations like fraud detection. This is because failing to detect or identify fraudulent transactions can be bring a lot of harm to many. For instance, missing transactions that are actually fraud can be extremely detrimental to the bank's reputation and users themselves as well. Therefore, in this context, even if some of the fraud transactions are missed or not detected, it means that the model is not good enough to be put into practice and protecting the users from fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the automated fraud detection model definitely is promising in that it brings about great results overall, achieving a test precision of 0.9848 and test recall of 0.8227. However, I would not use the model in practice without further improvements or refinements, as the test recall is not great enough. Although the model's moderate recall shows that it misses some fraudulent transactions, its high accuracy suggests that it is very good at correctly predicting fraud when it does so. In this specific scenario, we should put more emphasis on recall over precision because avoiding missed fraud transactions is more important for credit fraud detection. Therefore, finding the right balance between precision and recall would make a better model that would accurately and reliably detect credit frauds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
